{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 安徽安庆市项目\n",
    "## 将MEIC中本地清单的范围设为0\n",
    "## `Set MEIC to 0 in Anqing`\n",
    "\n",
    "---\n",
    "*@author: Evan*\\\n",
    "*@date: 2023-10-05*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# silence the warning note\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import sys\n",
    "sys.path.append('../../src/')\n",
    "from namelist import *\n",
    "from integrate import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncfile = xr.open_dataset(progdir + 'GRIDCRO2D_2023141.nc')\n",
    "lon = ncfile.LON.squeeze()\n",
    "lat = ncfile.LAT.squeeze()\n",
    "\n",
    "shp = gpd.read_file(progdir + 'shapefile/Anqing/Anqing.shp')\n",
    "\n",
    "mask = polygon_to_mask(shp.geometry[0],lon,lat)\n",
    "mask_da = xr.DataArray(mask,dims=('ROW','COL'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MEIC\n",
    "依据2.2步骤中生成的LEAQ文件，生成一个全为0的nc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "leaq = xr.open_dataset(leaq_bio_file)\n",
    "leaq_zero = xr.Dataset()\n",
    "\n",
    "for coord_name, coord in leaq.coords.items():\n",
    "    leaq_zero[coord_name] = coord\n",
    "\n",
    "for var_name, var in leaq.variables.items():\n",
    "    if var_name not in leaq.coords:\n",
    "        leaq_zero[var_name] = var.copy(data=np.zeros_like(var.values))\n",
    "leaq_zero.to_netcdf(datadir + f'step2_meic_and_leaq/leaq_zero.ncf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sections = ['ind','pow','tra','res','agr']\n",
    "\n",
    "for sec in sections:\n",
    "    ds_A = xr.open_dataset(datadir + f'step2_meic_and_leaq/leaq_zero.ncf')\n",
    "    ds_B = xr.open_dataset(eval(f'meic_{sec}_file'))\n",
    "\n",
    "    merged = merge_datasets(mask_da,ds_A,ds_B)\n",
    "    merged.to_netcdf(datadir + f'step2_meic_and_leaq/emis.CN3AH_135X138.{sec}.ncf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LEAQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "meic = xr.open_dataset(meic_ind_file)\n",
    "meic_zero = xr.Dataset()\n",
    "\n",
    "for coord_name, coord in meic.coords.items():\n",
    "    meic_zero[coord_name] = coord\n",
    "\n",
    "for var_name, var in meic.variables.items():\n",
    "    if var_name not in meic.coords:\n",
    "        meic_zero[var_name] = var.copy(data=np.zeros_like(var.values))\n",
    "meic_zero.to_netcdf(datadir + f'step2_meic_and_leaq/meic_zero.ncf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sections = ['bio','bol','bld','dst','elc','rod','nro','pet','sol','oth']\n",
    "\n",
    "for sec in sections:\n",
    "    ds_A = xr.open_dataset(eval(f'leaq_{sec}_file'))\n",
    "    ds_B = xr.open_dataset(datadir + f'step2_meic_and_leaq/meic_zero.ncf')\n",
    "\n",
    "    merged = merge_datasets(mask_da,ds_A,ds_B)\n",
    "    merged.to_netcdf(datadir + f'step2_meic_and_leaq/emis.CN3AH_135X138.{sec}.ncf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
